"""
Dataset'i train/val/test olarak bÃ¶ler
YOLO eÄŸitimi iÃ§in hazÄ±rlar
"""

import os
import shutil
import random
from pathlib import Path

# ============== AYARLAR ==============
IMAGES_DIR = r"D:\repos\Basketball_App\BasketballAIApp\Datasets\frames_output\hepsi"
LABELS_DIR = r"D:\repos\Basketball_App\BasketballAIApp\Datasets\frames_output\labels"
OUTPUT_DIR = r"D:\repos\Basketball_App\BasketballAIApp\Datasets\yolo_dataset"

# BÃ¶lme oranlarÄ± (toplam 1.0 olmalÄ±)
TRAIN_RATIO = 0.7   # %70 train
VAL_RATIO = 0.2     # %20 validation
TEST_RATIO = 0.1    # %10 test

# SÄ±nÄ±f isimleri
CLASS_NAMES = ["basketball", "rim", "player"]

# Random seed (tekrarlanabilirlik iÃ§in)
RANDOM_SEED = 42
# =====================================

def create_yaml_config(output_dir, class_names):
    """YOLO iÃ§in data.yaml oluÅŸtur"""
    yaml_content = f"""# YOLO Dataset Configuration
path: {output_dir}
train: images/train
val: images/val
test: images/test

# Classes
names:
"""
    for i, name in enumerate(class_names):
        yaml_content += f"  {i}: {name}\n"
    
    yaml_path = Path(output_dir) / "data.yaml"
    with open(yaml_path, "w") as f:
        f.write(yaml_content)
    
    return yaml_path

def split_dataset():
    random.seed(RANDOM_SEED)
    
    # TÃ¼m resimleri bul
    image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        image_files.extend(Path(IMAGES_DIR).glob(ext))
    
    # Sadece etiketi olan resimleri al
    valid_files = []
    for img_path in image_files:
        label_path = Path(LABELS_DIR) / (img_path.stem + ".txt")
        if label_path.exists():
            # BoÅŸ olmayan etiketleri kontrol et
            with open(label_path) as f:
                if f.read().strip():
                    valid_files.append(img_path)
    
    print(f"Toplam etiketli resim: {len(valid_files)}")
    
    # KarÄ±ÅŸtÄ±r
    random.shuffle(valid_files)
    
    # BÃ¶l
    total = len(valid_files)
    train_end = int(total * TRAIN_RATIO)
    val_end = train_end + int(total * VAL_RATIO)
    
    splits = {
        "train": valid_files[:train_end],
        "val": valid_files[train_end:val_end],
        "test": valid_files[val_end:]
    }
    
    print(f"\nBÃ¶lme sonuÃ§larÄ±:")
    print(f"  Train: {len(splits['train'])} resim")
    print(f"  Val:   {len(splits['val'])} resim")
    print(f"  Test:  {len(splits['test'])} resim")
    
    # KlasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur
    for split_name in ["train", "val", "test"]:
        os.makedirs(Path(OUTPUT_DIR) / "images" / split_name, exist_ok=True)
        os.makedirs(Path(OUTPUT_DIR) / "labels" / split_name, exist_ok=True)
    
    # DosyalarÄ± kopyala
    print("\nDosyalar kopyalanÄ±yor...")
    
    for split_name, files in splits.items():
        for img_path in files:
            # Resmi kopyala
            dest_img = Path(OUTPUT_DIR) / "images" / split_name / img_path.name
            shutil.copy2(img_path, dest_img)
            
            # Etiketi kopyala
            label_path = Path(LABELS_DIR) / (img_path.stem + ".txt")
            dest_label = Path(OUTPUT_DIR) / "labels" / split_name / (img_path.stem + ".txt")
            shutil.copy2(label_path, dest_label)
    
    # YAML config oluÅŸtur
    yaml_path = create_yaml_config(OUTPUT_DIR, CLASS_NAMES)
    
    # classes.txt oluÅŸtur
    classes_path = Path(OUTPUT_DIR) / "classes.txt"
    with open(classes_path, "w") as f:
        for name in CLASS_NAMES:
            f.write(f"{name}\n")
    
    print("\n" + "=" * 50)
    print("DATASET HAZIR!")
    print("=" * 50)
    print(f"\nğŸ“ Ã‡Ä±ktÄ± klasÃ¶rÃ¼: {OUTPUT_DIR}")
    print(f"ğŸ“„ YOLO config: {yaml_path}")
    print(f"\nğŸ“Š Ä°statistikler:")
    print(f"   Train: {len(splits['train'])} resim ({TRAIN_RATIO*100:.0f}%)")
    print(f"   Val:   {len(splits['val'])} resim ({VAL_RATIO*100:.0f}%)")
    print(f"   Test:  {len(splits['test'])} resim ({TEST_RATIO*100:.0f}%)")
    
    print(f"\nğŸš€ YOLO eÄŸitimi iÃ§in kullanÄ±m:")
    print(f"   yolo detect train data={yaml_path} model=yolov8n.pt epochs=100")
    
    return OUTPUT_DIR

if __name__ == "__main__":
    split_dataset()

